{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeguxq0X8QEznVPPbFS6Sv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0269_natural_language_processing/blob/main/resources/cloud_classification_ccsn_ViT_kfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloud Image Classification using Vision Transformers with Stratified K-Fold Cross Validation\n"
      ],
      "metadata": {
        "id": "Ltlbw2CikP_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7VyOGXbkNwJ"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r \"/content/drive/My Drive/img_satelite/classificacao/CCSN/\" \"ccsn_full\""
      ],
      "metadata": {
        "id": "68Nn5rzCkPY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install timm==0.3.2\n",
        "#!pip install -U transformers\n",
        "#!pip install -U scikit-learn\n",
        "!pip install focal-loss\n",
        "#!sudo apt -qq install git-lfs\n",
        "#!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "sjjuPWctXrxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,GlobalAveragePooling2D ,MaxPooling2D,Activation,Flatten,Conv2D,BatchNormalization,Dropout,Input,Reshape\n",
        "from keras.models import Sequential,Model\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from pathlib import Path\n",
        "import dill\n",
        "import pandas as pd\n",
        "from huggingface_hub import HfApi, Repository\n",
        "from transformers import ViTFeatureExtractor,TFViTModel,TFDeiTModel,ViTForImageClassification, ViTConfig,TFViTForImageClassification,DeiTForImageClassification,BeitForImageClassification,DeiTFeatureExtractor,BeitFeatureExtractor\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow_addons as tfa\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')"
      ],
      "metadata": {
        "id": "RP4M1K9DkWdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_focal_loss(alpha, gamma=2.):\n",
        "\n",
        "    alpha = np.array(alpha, dtype=np.float32)\n",
        "\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Compute mean loss in mini_batch\n",
        "        return K.mean(K.sum(loss, axis=-1))\n",
        "\n",
        "    return categorical_focal_loss_fixed\n"
      ],
      "metadata": {
        "id": "mnpKKHonBiVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = 'ccsn_full'"
      ],
      "metadata": {
        "id": "YGMhz6mNkWiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modelo"
      ],
      "metadata": {
        "id": "NapowZCkf1U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_model(sel_model,learning_rate,activation_f,num_labels,prob,number_of_neurons):\n",
        "\n",
        "    if sel_model == 'vit':\n",
        "        feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "        #model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "        model = TFViTForImageClassification.from_pretrained(\n",
        "            'google/vit-base-patch16-224-in21k',\n",
        "            num_labels=num_labels)\n",
        "    else:# sel_model == 'deit':\n",
        "        feature_extractor = DeiTFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
        "        model = TFDeiTModel.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
        "    #else:\n",
        "        #feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224')\n",
        "        #model = TFBeitModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "    \n",
        "    #model.compile(optimizer=\"adam\")\n",
        "    \n",
        "    return feature_extractor,model"
      ],
      "metadata": {
        "id": "JybMLa7jf18m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the image generator objects"
      ],
      "metadata": {
        "id": "IvyUuPWd-0PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "list_subfolders = os.listdir(path_data)\n",
        "    \n",
        "list_subfolders.sort()\n",
        "\n",
        "dataset_dict = {}\n",
        "\n",
        "dataset_dict['filename'] = []\n",
        "dataset_dict['label'] = []\n",
        "\n",
        "for folder in list_subfolders:\n",
        "\n",
        "    list_images_path = os.listdir(path_data+\"/\"+folder)\n",
        "    \n",
        "    list_images_path.sort()\n",
        "\n",
        "    for image_name in list_images_path:\n",
        "\n",
        "        dataset_dict['filename'].append(folder+\"/\"+image_name)\n",
        "\n",
        "        dataset_dict['label'].append(folder)"
      ],
      "metadata": {
        "id": "pg-mszmnynMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(dataset_dict)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sWIoA6mMyqci",
        "outputId": "f36b803e-24de-4cb3-8617-2ffa2753c661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            filename label\n",
              "0     Ac/Ac-N001.jpg    Ac\n",
              "1     Ac/Ac-N002.jpg    Ac\n",
              "2     Ac/Ac-N003.jpg    Ac\n",
              "3     Ac/Ac-N004.jpg    Ac\n",
              "4     Ac/Ac-N005.jpg    Ac\n",
              "...              ...   ...\n",
              "2538  St/St-N198.jpg    St\n",
              "2539  St/St-N199.jpg    St\n",
              "2540  St/St-N200.jpg    St\n",
              "2541  St/St-N201.jpg    St\n",
              "2542  St/St-N202.jpg    St\n",
              "\n",
              "[2543 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-606acb9d-170d-4657-8921-f8de8045dd69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ac/Ac-N001.jpg</td>\n",
              "      <td>Ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ac/Ac-N002.jpg</td>\n",
              "      <td>Ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ac/Ac-N003.jpg</td>\n",
              "      <td>Ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ac/Ac-N004.jpg</td>\n",
              "      <td>Ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ac/Ac-N005.jpg</td>\n",
              "      <td>Ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2538</th>\n",
              "      <td>St/St-N198.jpg</td>\n",
              "      <td>St</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2539</th>\n",
              "      <td>St/St-N199.jpg</td>\n",
              "      <td>St</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2540</th>\n",
              "      <td>St/St-N200.jpg</td>\n",
              "      <td>St</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2541</th>\n",
              "      <td>St/St-N201.jpg</td>\n",
              "      <td>St</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2542</th>\n",
              "      <td>St/St-N202.jpg</td>\n",
              "      <td>St</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2543 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-606acb9d-170d-4657-8921-f8de8045dd69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-606acb9d-170d-4657-8921-f8de8045dd69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-606acb9d-170d-4657-8921-f8de8045dd69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def returnModel(num_labels,activation_f,batch_size):\n",
        "\n",
        "    configuration = ViTConfig()\n",
        "\n",
        "    # Initializing a model from the vit-base-patch16-224 style configuration\n",
        "    model = TFViTModel(configuration)\n",
        "    \n",
        "    base_model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "    # Flipping and rotating images\n",
        "    #data_augmentation = Sequential(\n",
        "    #    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n",
        "    #im.transpose(2,0,1)\n",
        "    #)\n",
        "\n",
        "    # Freeze base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Create new model\n",
        "    inputs = Input(shape = (3,224, 224))\n",
        "    #x = data_augmentation(inputs)   # apply data augmentation\n",
        "    x = base_model(inputs, training=False)[0]\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_labels, activation=activation_f)(x)\n",
        "    model_vit = Model(inputs, outputs)\n",
        "    return model_vit"
      ],
      "metadata": {
        "id": "CjrnxVJVU0in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf_outer = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
        "\n",
        "outer_results = list()\n",
        "\n",
        "num_labels = 11\n",
        "sel_model = 'vit'\n",
        "activation_f = 'softmax'\n",
        "lr = 5e-4\n",
        "epochs = 15\n",
        "prob = 0.5\n",
        "batch_size = 32\n",
        "aug = False\n",
        "focal = False\n",
        "\n",
        "X = np.array(df['filename'])\n",
        "y = np.array(df['label'])\n",
        "\n",
        "f1scoretfa = tfa.metrics.F1Score(num_classes=num_labels, average='macro',threshold=0.5)"
      ],
      "metadata": {
        "id": "Sfy_XxQiyv9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_f1score = []\n",
        "overall_test_f1score = []\n",
        "test_fold = []\n",
        "test_loss = []\n",
        "\n",
        "trial = 1\n",
        "\n",
        "agnostic_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "if aug == True:\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,width_shift_range=0.2, height_shift_range=0.2,brightness_range=[0.4,1.5],zoom_range=0.3)\n",
        "\n",
        "for train_ix, test_ix in skf_outer.split(X,y):\n",
        "\n",
        "    val_f1score = []\n",
        "    val_loss = []\n",
        "    \n",
        "    train_list = []\n",
        "    #y_train_list = []\n",
        "    test_list = []\n",
        "\n",
        "    for ind in train_ix:\n",
        "        train_list.append([X[ind],y[ind]])\n",
        "        #y_train_list.append(y[ind])\n",
        "    \n",
        "    for ind in test_ix:\n",
        "        test_list.append([X[ind],y[ind]])\n",
        "\n",
        "    X_train = pd.DataFrame(train_list, columns =['filename','label'])\n",
        "    X_test = pd.DataFrame(test_list, columns =['filename','label'])\n",
        "\n",
        "    test_generator = agnostic_datagen.flow_from_dataframe(X_test, directory = path_data,\n",
        "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
        "                            target_size = (224,224),\n",
        "                            color_mode='rgb',\n",
        "                            batch_size= batch_size,\n",
        "\t\t\t\t\t\t\tclass_mode = \"categorical\", shuffle = True)\n",
        "    \n",
        "    skf_inner = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)\n",
        "\n",
        "    nfold = 1\n",
        "\n",
        "    for train_index, val_index in skf_inner.split(X_train['filename'],X_train['label']):\n",
        "        \n",
        "        train_list = []\n",
        "        valid_list = []\n",
        "\n",
        "        for ind in train_ix:\n",
        "            train_list.append([X[ind],y[ind]])\n",
        "        \n",
        "        for ind in test_ix:\n",
        "            valid_list.append([X[ind],y[ind]])\n",
        "\n",
        "        X_train = pd.DataFrame(train_list, columns =['filename','label'])\n",
        "        X_valid = pd.DataFrame(valid_list, columns =['filename','label'])\n",
        "\n",
        "\n",
        "        train_generator = train_datagen.flow_from_dataframe(X_train, directory = path_data,\n",
        "                                                               x_col = \"filename\", y_col = \"label\",\n",
        "                                                               target_size = (224,224),\n",
        "                                                               color_mode='rgb',\n",
        "                                                               batch_size= batch_size,\n",
        "                                                               class_mode = \"categorical\", shuffle = True)\n",
        "        \n",
        "        validation_generator = agnostic_datagen.flow_from_dataframe(X_valid, directory = path_data,\n",
        "                                                                 x_col = \"filename\", y_col = \"label\",\n",
        "                                                                 target_size = (224,224),\n",
        "                                                                 color_mode='rgb',\n",
        "                                                                 batch_size= batch_size,\n",
        "                                                                 class_mode = \"categorical\")\n",
        "        \n",
        "        #feature_extractor,vit_model = classification_model(sel_model,lr,activation_f,num_labels,prob,num_neurons)\n",
        "        model = returnModel(num_labels,activation_f,batch_size)\n",
        "        #print(model.summary())\n",
        "        \n",
        "        #fname = \"weights-improvement-{epoch:02d}-{val_f1_score:.2f}.hdf5\"\n",
        "        \n",
        "        #checkpoint = ModelCheckpoint(fname, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "        #early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "        #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, min_lr=0.000002)\n",
        "        #callbacklist = [early_stopping,reduce_lr]\n",
        "\n",
        "        adams_family = Adam(learning_rate=lr,decay=0.01)\n",
        "\n",
        "        if focal == True:\n",
        "            loss_function = categorical_focal_loss(gamma=2)\n",
        "        else:\n",
        "            loss_function = 'categorical_crossentropy'\n",
        "        \n",
        "        model.compile(optimizer = adams_family,\n",
        "                      loss = loss_function,\n",
        "                      metrics = [f1scoretfa])\n",
        "\n",
        "        history_fine = model.fit(train_generator,\n",
        "                         epochs=epochs,\n",
        "                         batch_size=batch_size,\n",
        "                         validation_data=validation_generator)#,\n",
        "                         #callbacks=callbacklist\n",
        "                         #)\n",
        "        \n",
        "        f1 = history_fine.history['f1_score']\n",
        "        val_f1 = history_fine.history['val_f1_score']\n",
        "\n",
        "        loss = history_fine.history['loss']\n",
        "        val_loss = history_fine.history['val_loss']\n",
        "\n",
        "        val_f1score.append(np.mean(np.array(val_f1)))\n",
        "        val_loss.append(np.mean(np.array(val_loss)))\n",
        "\n",
        "        nfold+=1\n",
        "\n",
        "        print(f'NFold {nfold} Validation loss: {val_loss} / Validation f-score: {val_f1}')\n",
        "        #del model\n",
        "\n",
        "        y_prob = model.predict(test_generator)\n",
        "        y_pred = np.argmax(y_prob,axis=1)\n",
        "        y_true = test_generator.classes\n",
        "\n",
        "        f1score = f1_score(y_true, y_pred, average='macro')\n",
        "        #score = model.evaluate(test_generator,batch_size=batch_size) \n",
        "        #print(f'Trial {trial} Test loss: {score[0]} / Test accuracy: {score[1]}\\n')\n",
        "\n",
        "        trial+=1\n",
        "\n",
        "        test_f1score.append(f1score)\n",
        "        #test_loss.append(np.mean(np.array(val_loss)))\n",
        "\n",
        "        del model\n",
        "        \n",
        "    overall_test_f1score.append(np.mean(np.array(test_f1score)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jDtx3iM-SdJ",
        "outputId": "964eb065-5678-455b-d232-65813a2fe903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 509 validated image filenames belonging to 11 classes.\n",
            "Found 2034 validated image filenames belonging to 11 classes.\n",
            "Found 509 validated image filenames belonging to 11 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFViTModel.\n",
            "\n",
            "All the layers of TFViTModel were initialized from the model checkpoint at google/vit-base-patch16-224-in21k.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "64/64 [==============================] - 57s 721ms/step - loss: 2.6520 - f1_score: 0.2770 - val_loss: 2.1497 - val_f1_score: 0.3137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "y_prob = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_prob,axis=1)\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ],
      "metadata": {
        "id": "3gLrnelbdd_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "z = confusion_matrix(y_true, y_pred)\n",
        "z"
      ],
      "metadata": {
        "id": "iLXz5i8Ijw2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred, target_names=classes))"
      ],
      "metadata": {
        "id": "aKSmh_3omiF2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}