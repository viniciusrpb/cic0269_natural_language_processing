{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMne+hr/94O3i0vhDS5MS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0269_natural_language_processing/blob/main/lectures/aula_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicação: Reconhecimento de Entidades Nomeadas\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/conll2003\n",
        "\n",
        "\n",
        "CoNLL 2003\n",
        "This dataset includes 1,393 English and 909 German news articles. The English-language corpus is free, but the German corpus comes at $75, unfortunately. This is the only corpus that costs something in this post. To build the English-language corpus you need the RCV1 Reuters corpus. You will obtain access a couple days after submitting the organisational and individual agreement at no charge.\n",
        "\n",
        "Entities are annotated with LOC (location), ORG (organisation), PER (person) and MISC (miscellaneous). "
      ],
      "metadata": {
        "id": "bwHBSHrMVlJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xzqTxT27ZZL"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow-datasets\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install keras-crf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Embedding,Dropout,LSTM,Bidirectional,TimeDistributed\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "from keras_crf import CRFModel\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "YurnZIGf8fkS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessDataFrame(df):\n",
        "\n",
        "    dic = {}\n",
        "    dic['tokens'] = []\n",
        "\n",
        "    for text in df['tokens']:\n",
        "        tokens = []\n",
        "        for x in text:\n",
        "            tokens.append(x.decode('utf-8'))\n",
        "        l = \" \".join(tokens)\n",
        "        dic['tokens'].append(l.split())\n",
        "        \n",
        "    res_df = pd.DataFrame.from_dict(dic)\n",
        "    res_df['ner'] = df['ner']\n",
        "    return res_df"
      ],
      "metadata": {
        "id": "wbSPBoYBausW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tfds.load('conll2003', split='train', shuffle_files=True)\n",
        "ds_valid = tfds.load('conll2003', split='dev', shuffle_files=False)\n",
        "ds_test = tfds.load('conll2003', split='test', shuffle_files=False)"
      ],
      "metadata": {
        "id": "ZQMmPm1A8j3C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = preprocessDataFrame(tfds.as_dataframe(ds_train))\n",
        "df_valid = preprocessDataFrame(tfds.as_dataframe(ds_valid))\n",
        "df_test = preprocessDataFrame(tfds.as_dataframe(ds_test))"
      ],
      "metadata": {
        "id": "PVBs34YrVR6t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "gJ77VPYStB6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1d03571f-ccdc-49e4-8df8-ce3b2a490120"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tokens  \\\n",
              "0      [\", If, they, 're, saying, at, least, 20, perc...   \n",
              "1      [Lauck, 's, lawyer, vowed, he, would, appeal, ...   \n",
              "2      [Thailand, 's, powerful, military, thinks, the...   \n",
              "3      [A, forensic, scientist, who, examined, the, s...   \n",
              "4                  [Werder, Bremen, 3, 0, 1, 2, 4, 6, 1]   \n",
              "...                                                  ...   \n",
              "14037                   [\", He, was, not, involved, ...]   \n",
              "14038  [\", It, goes, without, saying, that, we, 're, ...   \n",
              "14039                                       [Bowling, :]   \n",
              "14040                                 [National, League]   \n",
              "14041                                 [LOME, 1996-08-25]   \n",
              "\n",
              "                                                     ner  \n",
              "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2      [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, ...  \n",
              "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
              "4                            [3, 4, 0, 0, 0, 0, 0, 0, 0]  \n",
              "...                                                  ...  \n",
              "14037                                 [0, 0, 0, 0, 0, 0]  \n",
              "14038  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
              "14039                                             [0, 0]  \n",
              "14040                                             [7, 8]  \n",
              "14041                                             [5, 0]  \n",
              "\n",
              "[14042 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03208342-d636-4c0b-8939-cb2b043d0101\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\", If, they, 're, saying, at, least, 20, perc...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Lauck, 's, lawyer, vowed, he, would, appeal, ...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Thailand, 's, powerful, military, thinks, the...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[A, forensic, scientist, who, examined, the, s...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Werder, Bremen, 3, 0, 1, 2, 4, 6, 1]</td>\n",
              "      <td>[3, 4, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14037</th>\n",
              "      <td>[\", He, was, not, involved, ...]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14038</th>\n",
              "      <td>[\", It, goes, without, saying, that, we, 're, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14039</th>\n",
              "      <td>[Bowling, :]</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14040</th>\n",
              "      <td>[National, League]</td>\n",
              "      <td>[7, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14041</th>\n",
              "      <td>[LOME, 1996-08-25]</td>\n",
              "      <td>[5, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14042 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03208342-d636-4c0b-8939-cb2b043d0101')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03208342-d636-4c0b-8939-cb2b043d0101 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03208342-d636-4c0b-8939-cb2b043d0101');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label2int():\n",
        "    iob_labels = [\"B\", \"I\"]\n",
        "    ner_labels = [\"PER\", \"ORG\", \"LOC\", \"MISC\"]\n",
        "    all_labels = [(label1, label2) for label2 in ner_labels for label1 in iob_labels]\n",
        "    all_labels = [\"-\".join([a, b]) for a, b in all_labels]\n",
        "    dic = dict(zip(range(1, len(all_labels) + 1), all_labels))\n",
        "    dic[0] = 'O'\n",
        "    return dic "
      ],
      "metadata": {
        "id": "i5qwk5AwWGiu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2tag = label2int()\n",
        "\n",
        "int2tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wburyOkU0tsa",
        "outputId": "6f5e3bf1-3bde-452d-88cc-80061ec47564"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'B-PER',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-ORG',\n",
              " 4: 'I-ORG',\n",
              " 5: 'B-LOC',\n",
              " 6: 'I-LOC',\n",
              " 7: 'B-MISC',\n",
              " 8: 'I-MISC',\n",
              " 0: 'O'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2int = {}\n",
        "for key in int2tag:\n",
        "    value = int2tag[key]\n",
        "    tag2int[value] = key\n",
        "print(tag2int)\n",
        "\n",
        "num_labels = len(tag2int)"
      ],
      "metadata": {
        "id": "NKGag80BWVX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69464419-d299-4a3e-b9bc-54f9250a5954"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8, 'O': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria o vocabulário"
      ],
      "metadata": {
        "id": "e7euVuZV9_Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2index = {}\n",
        "word2index['<OOV>'] = 0\n",
        "word2index['<BEG>'] = 1\n",
        "word2index['<END>'] = 2\n",
        "\n",
        "ind = 3\n",
        "for text in df_train['tokens']:\n",
        "    for word in text:\n",
        "        if word not in word2index:\n",
        "            word2index[word] = ind\n",
        "            ind+=1\n",
        "\n",
        "index2word = {}\n",
        "for key in word2index:\n",
        "    value = word2index[key]\n",
        "    index2word[value] = key"
      ],
      "metadata": {
        "id": "h8ydPLuy9_an"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rebuild_datasets(df,labels):\n",
        "\n",
        "    data = []\n",
        "    novel_labels = []\n",
        "\n",
        "    idx = 0\n",
        "    for text in df:\n",
        "\n",
        "        data.append(['<BEG>'])\n",
        "        novel_labels.append(0)\n",
        "\n",
        "        for i in range(0,len(text)):\n",
        "            lista = ['<BEG>']+text[:i+1]\n",
        "            data.append(lista)\n",
        "            if i < len(text)-1:\n",
        "                novel_labels.append(labels[idx][i])\n",
        "            else:\n",
        "                novel_labels.append(0)\n",
        "        idx+=1\n",
        "\n",
        "        data.append(lista+['<END>'])\n",
        "        novel_labels.append(0)\n",
        "\n",
        "    return data,novel_labels"
      ],
      "metadata": {
        "id": "RMv8s9mC89n3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train_int = rebuild_datasets(df_train['tokens'],df_train['ner'])\n",
        "x_valid,y_valid_int = rebuild_datasets(df_valid['tokens'],df_valid['ner'])\n",
        "x_test,y_test_int = rebuild_datasets(df_test['tokens'],df_test['ner'])"
      ],
      "metadata": {
        "id": "wf9UeaQM8-yw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se está tudo certo"
      ],
      "metadata": {
        "id": "pF8zNwDQeUOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,word in enumerate(x_train[33]):\n",
        "    print(f'Word: {word} text label: {int2tag[y_train_int[i]]} int label: {y_train_int[i]} ')"
      ],
      "metadata": {
        "id": "PbEnKVm2_Zhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7eabacd-994e-406c-b127-ac6754f48b52"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: <BEG> text label: O int label: 0 \n",
            "Word: \" text label: O int label: 0 \n",
            "Word: If text label: O int label: 0 \n",
            "Word: they text label: O int label: 0 \n",
            "Word: 're text label: O int label: 0 \n",
            "Word: saying text label: O int label: 0 \n",
            "Word: at text label: O int label: 0 \n",
            "Word: least text label: O int label: 0 \n",
            "Word: 20 text label: O int label: 0 \n",
            "Word: percent text label: O int label: 0 \n",
            "Word: , text label: O int label: 0 \n",
            "Word: then text label: O int label: 0 \n",
            "Word: their text label: O int label: 0 \n",
            "Word: internal text label: O int label: 0 \n",
            "Word: forecasts text label: O int label: 0 \n",
            "Word: are text label: O int label: 0 \n",
            "Word: probably text label: O int label: 0 \n",
            "Word: saying text label: O int label: 0 \n",
            "Word: 25 text label: O int label: 0 \n",
            "Word: or text label: O int label: 0 \n",
            "Word: 30 text label: O int label: 0 \n",
            "Word: percent text label: O int label: 0 \n",
            "Word: , text label: O int label: 0 \n",
            "Word: \" text label: O int label: 0 \n",
            "Word: said text label: O int label: 0 \n",
            "Word: one text label: O int label: 0 \n",
            "Word: Sydney text label: B-LOC int label: 5 \n",
            "Word: media text label: O int label: 0 \n",
            "Word: analyst text label: O int label: 0 \n",
            "Word: who text label: O int label: 0 \n",
            "Word: declined text label: O int label: 0 \n",
            "Word: to text label: O int label: 0 \n",
            "Word: be text label: O int label: 0 \n",
            "Word: named text label: O int label: 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(sentence) for sentence in x_train])\n",
        "max_length"
      ],
      "metadata": {
        "id": "E40GuN4S--9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c1b6c1-9d32-4614-cc05-ce3a5b6a08d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text2sequences(data,vocab):\n",
        "    corpus_int = []\n",
        "    for instance in data:\n",
        "        instance_int = []\n",
        "        for term in instance:\n",
        "            if term in vocab:\n",
        "                instance_int.append(vocab[term])\n",
        "            else:\n",
        "                instance_int.append(vocab['<OOV>'])\n",
        "        corpus_int.append(instance_int)\n",
        "    \n",
        "    return corpus_int"
      ],
      "metadata": {
        "id": "gN6nP0bMAGPz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = text2sequences(x_train,word2index)\n",
        "valid_sequences = text2sequences(x_valid,word2index)\n",
        "test_sequences = text2sequences(x_test,word2index)"
      ],
      "metadata": {
        "id": "2gcb70fIAAvO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trunc_type = 'post'\n",
        "padding_type = 'pre'\n",
        "\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "AwDZSyDDCB8Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train_int)\n",
        "y_valid = to_categorical(y_valid_int)\n",
        "y_test = to_categorical(y_test_int)"
      ],
      "metadata": {
        "id": "y7dUqlViCLL3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2index)"
      ],
      "metadata": {
        "id": "948xJCRTCnae"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size+3,output_dim=64,input_length=max_length))\n",
        "model.add(Bidirectional(LSTM(256,activation='relu')))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_labels,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXktiN4VEUmR",
        "outputId": "ed0a037f-ff42-46fc-cfcd-73e07e5500e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcY5UK9kEt5P",
        "outputId": "11bf531b-4546-47d7-8397-2adef43037c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 115, 64)           1512256   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 512)              657408    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 4617      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,174,281\n",
            "Trainable params: 2,174,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1scoretfa = tfa.metrics.F1Score(num_classes=num_labels, average='macro',threshold=0.5)\n",
        "\n",
        "sgd = SGD(learning_rate = 0.00005)\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy',f1scoretfa])\n",
        "history_fine = model.fit(train_padded,y_train,batch_size=32,validation_data=(valid_padded,y_valid),epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQyNvJ2pEjuZ",
        "outputId": "8cc9b5dc-0385-4110-b535-c84a4474211d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7241/7241 [==============================] - 3417s 471ms/step - loss: 2.0125 - accuracy: 0.8354 - f1_score: 0.0000e+00 - val_loss: 1.8339 - val_accuracy: 0.8538 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/10\n",
            "7241/7241 [==============================] - 3334s 460ms/step - loss: 1.6453 - accuracy: 0.8562 - f1_score: 0.0000e+00 - val_loss: 1.4551 - val_accuracy: 0.8538 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/10\n",
            "7241/7241 [==============================] - 3424s 473ms/step - loss: 1.2567 - accuracy: 0.8562 - f1_score: 7.4978e-04 - val_loss: 1.0641 - val_accuracy: 0.8538 - val_f1_score: 0.0000e+00\n",
            "Epoch 4/10\n",
            "3329/7241 [============>.................] - ETA: 30:14 - loss: 0.9796 - accuracy: 0.8571 - f1_score: 0.0742"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_fine.history['loss'])\n",
        "plt.plot(history_fine.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set','validation set'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kQInP_lcFyMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_fine.history['f1_score'])\n",
        "plt.plot(history_fine.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set','validation set'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NgUE31ItF267"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste"
      ],
      "metadata": {
        "id": "F6Vneb89F4WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(test_padded)\n",
        "y_pred = np.argmax(y_prob,axis=1)"
      ],
      "metadata": {
        "id": "VeyDxErCF49M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_int,y_pred))"
      ],
      "metadata": {
        "id": "uOkDZ9JrF6H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment"
      ],
      "metadata": {
        "id": "Mogb-FZ0F-JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca_teste = \"Mayara is living in Spain which its land urges for coffee\"\n",
        "sentenca_int = text2sequences(sentenca_teste,word2index)\n",
        "sentenca_padded = pad_sequences(sentenca_int, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "y_prob = model.predict(sentenca_padded)\n",
        "y_pred = np.argmax(y_prob,axis=1)\n",
        "\n",
        "for idx,word in enumerate(sentenca_teste):\n",
        "    print(f'{word} is label {int2tag[y_pred[idx]]}')"
      ],
      "metadata": {
        "id": "ZI3t_a1bF_Rz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}